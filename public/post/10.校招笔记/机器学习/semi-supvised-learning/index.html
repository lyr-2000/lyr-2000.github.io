<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>半监督学习 - Even - A super concise theme for Hugo</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="LYR" /><meta name="description" content="半监督学习(Semi-supervised learning) 半监督学习的Classification问题 李宏毅教授半监督学习视频 知乎半监督学习笔记 1. intro 1.1 半监" /><meta name="keywords" content="LYR的文档站, LYR的个人博客, even" />






<meta name="generator" content="Hugo 0.86.0 with theme even" />


<link rel="canonical" href="http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/semi-supvised-learning/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.b5a744db6de49a86cadafb3b70f555ab443f83c307a483402259e94726b045ff.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="半监督学习" />
<meta property="og:description" content="半监督学习(Semi-supervised learning) 半监督学习的Classification问题 李宏毅教授半监督学习视频 知乎半监督学习笔记 1. intro 1.1 半监" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/semi-supvised-learning/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-08-14T22:43:02+08:00" />
<meta property="article:modified_time" content="2021-08-14T22:43:02+08:00" />

<meta itemprop="name" content="半监督学习">
<meta itemprop="description" content="半监督学习(Semi-supervised learning) 半监督学习的Classification问题 李宏毅教授半监督学习视频 知乎半监督学习笔记 1. intro 1.1 半监"><meta itemprop="datePublished" content="2021-08-14T22:43:02+08:00" />
<meta itemprop="dateModified" content="2021-08-14T22:43:02+08:00" />
<meta itemprop="wordCount" content="2565">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="半监督学习"/>
<meta name="twitter:description" content="半监督学习(Semi-supervised learning) 半监督学习的Classification问题 李宏毅教授半监督学习视频 知乎半监督学习笔记 1. intro 1.1 半监"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">LYR的文档站</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">首页</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">归档页</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">标签</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">分类</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">关于</li>
      </a><a href="/friends">
        <li class="mobile-menu-item">大佬</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">LYR的文档站</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">首页</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">归档页</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">标签</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">分类</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">关于</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/friends">大佬</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">半监督学习</h1>

      <div class="post-meta">
        <span class="post-time"> 2021-08-14 </span>
        
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#半监督学习semi-supervised-learning">半监督学习(Semi-supervised learning)</a>
          <ul>
            <li><a href="#1-intro">1. intro</a></li>
            <li><a href="#2-generative-model-生成模型">2. Generative Model &ldquo;生成模型&rdquo;</a></li>
            <li><a href="#3-low-density-separation-非黑即白">3. Low-density Separation &ldquo;非黑即白&rdquo;</a></li>
            <li><a href="#4-smoothness-assumption-近朱者赤--近墨者黑">4. Smoothness Assumption &ldquo;近朱者赤 , 近墨者黑&rdquo;</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <h2 id="半监督学习semi-supervised-learning">半监督学习(Semi-supervised learning)</h2>
<p>半监督学习的Classification问题</p>
<blockquote>
<p><a href="https://www.youtube.com/watch?v=fX_guE7JNnY">李宏毅教授半监督学习视频</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/34459160">知乎半监督学习笔记</a></p>
</blockquote>
<h3 id="1-intro">1. intro</h3>
<h4 id="11-半监督学习数据集分类">1.1 半监督学习数据集分类</h4>
<ul>
<li>同时有两种数据集 : <strong>带标签的和不带标签的</strong></li>
<li>数据集的数量上<strong>不带标签的数据  &raquo; 集带标签的</strong></li>
</ul>
<h4 id="12-半监督学习分类">1.2 半监督学习分类</h4>
<p>半监督学习又可以分为两种 :</p>
<ol>
<li>Transductive learing : unlabeled data is the testing data</li>
</ol>
<p><strong>注意只用testing set的feature而没有用testing set的label</strong></p>
<ol start="2">
<li>Inductive leanring : unlabeled data is not the testing data</li>
</ol>
<h4 id="13-为什么我们要用半监督学习">1.3 为什么我们要用半监督学习?</h4>
<p>因为我们收集数据其实很简单, 但是收集一些带有&rsquo;label&rsquo;的数据却 expensive, 如果只用有label的数据集, 则数据集的数据很可能达不到机器学习训练数据集的标准.</p>
<h4 id="14-为什么半监督学习helps">1.4 为什么半监督学习helps?</h4>
<ul>
<li>
<p>The distribution of the unlabeled data tells us somethings. 虽然没有标签, 但是也告诉了我们一些信息!</p>
<p><img src='/image/semi-1.png' /></p>
</li>
</ul>
<center>只考虑有label data的数据集时我们的分类界</center>
<p><img src='/image/semi-2.png' /></p>
<center>考虑了unlabeled data(灰色的点)的时候, 我们会调整我们的分类界</center>
<h3 id="2-generative-model-生成模型">2. Generative Model &ldquo;生成模型&rdquo;</h3>
<p>首先复习一下什么在<strong>监督学习里面生成模型是怎么作用的</strong></p>
<h3 id="3-low-density-separation-非黑即白">3. Low-density Separation &ldquo;非黑即白&rdquo;</h3>
<ul>
<li>Assumption : 此种方式基于的假设是, <strong>在两个class的交接处是不会出现data的, 即data量很低</strong></li>
</ul>
<p><img src='/image/semi-3.png' /></p>
<p>如图, <strong>在两个class中间很容易区别</strong>, 且如果利用unlabeled data会得到跟好的决策界</p>
<h4 id="31-self-training-方法很常用的方法">3.1 Self-training 方法(很常用的方法)</h4>
<p>可以概括为以下的几个步骤:</p>
<ol>
<li>
<p>利用已经有<strong>label的dataset中训练出一个模型 : f</strong> , 训练的方法可以是任意的机器学习的方法.</p>
</li>
<li>
<p>将没有label的数据至于模型 f 中, 得到相应的标签 这里的数据集称为<strong>Pseudo-label</strong></p>
</li>
<li>
<p>然后从刚刚训练的Pseudo-label数据集中<strong>拿出一些数据加到label set</strong></p>
</li>
<li>
<p>形成新的数据集重复以上步骤</p>
</li>
</ol>
<p><strong>注意这种方法只能用在分类的问题上, 回归的没有任何作用的</strong></p>
<p>以<strong>神经网络作为训练模型举例</strong> :</p>
<p><img src='/image/semi-4.png' /></p>
<p>用已经训练好的模型去预测一个无标签的数据, 得到的向量为[0.7, 0.3], 即0.7概率在class1, 0.3概率在class2. 此时用self-training的方法和generative model的方法变产生了分歧</p>
<ul>
<li>self-training : 用<strong>Hard label</strong>(低密度的思想) ==&gt;即此时将数据归位class1, 即将该数据投入训练的标签为[1, 0]</li>
<li>generative model : 用 <strong>soft label</strong> ==&gt; 还是用[0.7, 0.3]的标签去投入训练从而没有任何作用</li>
</ul>
<h5 id="331-entropy-based-regularization">3.3.1 entropy-based Regularization</h5>
<p><strong>利用Hard-label的self-training的提高进阶版</strong></p>
<p><strong>引出问题</strong> : 由于利用hard-label的太过武断, 如果碰到两边class概率相差不多的情况下, 就直接归位其中略高的一类可能会产出归类错误.</p>
<p>从而引入了<strong>分布熵(distribution entropy)<strong>的概念来表示输出的分布的分散程度. 明显, 我们基于Low-density的是</strong>希望一个unlabel数据的输出的概率分布越集中越好</strong>.</p>
<p>如下举例子 :</p>
<p><img src='/image/semi-5.png' /></p>
<center>输出的概率分布集中在class1</center>
<p><img src='/image/semi-6.png' /></p>
<center>输出的概率分布集中在class5</center>
<p><img src='/image/semi-7.png' /></p>
<center>输出的概率分散于5个class</center>
<p>显然在<strong>基于非黑即白的</strong>假设中, 前两个是我们希望的.而最后一个输出的结果为[0.2, 0.2, 0.2, 0.2, 0.2]明显是非常差的结果</p>
<p>这种<strong>输出的概率分布的分散程度, 我们可以entropy来表示</strong> : 描述一个分布的分散程度的信息熵得公式为:</p>
<p>E(y$^u$)  = - <img src="https://latex.codecogs.com/svg.latex?\sum_{m-1}^{5}y_{m}^{u}ln(y_{m}^{u})" title="\sum_{m-1}^{5}y_{m}^{u}ln(y_{m}^{u})" /></p>
<p>**$y_{m}^{u}$ 为这个u这个unlabel数据的归位m类的概率**, 我们可以计算以上几种分布的信息熵</p>
<p>E(FirstOne) = E(SecondOne) = 0</p>
<p>E(ThirdOne) = ln(5)</p>
<p>总结来说 : <strong>信息熵越低的分布越集中</strong>, 这也是我们想要的结果</p>
<p>Based above : 我们可以在模型的Loss function中加入信息熵这一项, 从而得到新的Loss Function</p>
<p><img src='/image/semi-8.png' /></p>
<center>加入信息熵的损失函数
<p>基于这种方式, 由于这个式子依然是可以微分的, 所以我们依然可以用梯度下降的方法来优化这个函数</p>
<h3 id="4-smoothness-assumption-近朱者赤--近墨者黑">4. Smoothness Assumption &ldquo;近朱者赤 , 近墨者黑&rdquo;</h3>
<ul>
<li>
<p>Assumption : 如果两个数据, 有相似的x, 那么它们的label y 也会相似.</p>
</li>
<li>
<p>More precisely : unlabeled 数据不是均匀分布的(x is not uniform), 如果两个数据的 x 在<strong>高密度的区域</strong>是相近的, 那么他们的标签y就是一样的.</p>
</li>
</ul>
<p>显然在更加精确的描述下更为合理, 如下图:</p>
<p><img src='/image/semi-9.png' /></p>
<center>三个unlabeled点的分布和它们附近区域的分布</center>
<p>在这种假设下, x$^1$ 和 x$^2$ 在高密度的区域临近, 所以得出结论:</p>
<ul>
<li>x$^1$ 和 x$^2$ 是一类</li>
<li>x$^3$ 和 x$^2$ 不是一类</li>
</ul>
<p><strong>这种假设方法在image识别中可能不是太有用</strong></p>
<h4 id="41cluster-and-then-label-的方法">4.1Cluster and then label 的方法</h4>
<p>这种方式很容易实现, 假设我们只有两个分类class</p>
<p><img src='/image/semi-10.png' /></p>
<center>两个class的分布图
<ol>
<li>首先我们需要将所有的数据(包活label 和 unlabeled)进行聚类</li>
<li>划分出相应的<strong>高密度的区域</strong></li>
<li>根据每一个不同高密度区域的<strong>已知的label数据给这一整个数据区域的所有数据标上label</strong></li>
<li>将标完数据label的数据视为有标签的数据进行模型训练</li>
</ol>
<h4 id="42-graph-based-approach">4.2 Graph-based Approach</h4>
<h5 id="421-build-a-graph">4.2.1 Build a graph</h5>
<p><strong>核心点就是</strong> : How to know x$^1$ and x$^2$ are close in a high density region ?</p>
<p><img src='/image/semi-11.png' /></p>
<center>所有的数据表示为图中的点
<p>这种方法的思想就是 : 用<strong>图的方式</strong>去表示这些data points, <strong>如果不同的数据点在图中相连, 则归位一类. 否则无论它们距离有多近, 都不能算为一类</strong></p>
<p>难点在于, 如果去建立一个图:</p>
<ul>
<li>
<p>有些时候, Graph representation is nature to get sometimes E.g. Hyperlink of webpages(网页之间可以用超链接来表示亮点之间的连通), citation of papers (同理, 论文可以用Reference的方式表示)</p>
</li>
<li>
<p>一些时候只有自己凭借经验去建立这个Graph Representation. 通常是根据以下的流程</p>
<ol>
<li>
<p>Define the <strong>similarity</strong> s(x$^i$, x$^j$) between x$^i$, x$^j$ 即算出点之间的相似度</p>
</li>
<li>
<p>Add edge (算出相似度之后就可以画出graph) 建立graph也有以下几种方法:</p>
<ul>
<li>
<p>K Nearest Neighbor : 选取一个点周围的最近的三个点连接</p>
<p><img src='/image/semi-12.png' /></p>
</li>
<li>
<p>e-Neighborhood  选取一个点附近小于 e 的点连接</p>
<p><img src='/image/semi-12.png' /></p>
</li>
</ul>
</li>
</ol>
</li>
</ul>
<p><strong>Tips计算相似度常用的方法为 Gaussian Radial basis Function :</strong></p>
<p><img src="https://latex.codecogs.com/svg.latex?S(x^i&space;,&space;x^j)&space;=&space;exp(-\alpha&space;|x^i&space;-&space;x^j|^2)" title="S(x^i , x^j) = exp(-\alpha |x^i - x^j|^2)" /></p>
<h5 id="421-建立图后给unlabeled数据贴标签">4.2.1 建立图后给unlabeled数据贴标签</h5>
<p><img src='/image/semi-14.png' /></p>
<p>在建立了一个图之后, <strong>我们给已知的标签的数据其相邻的数据 其属于class1的概率会增加</strong>, 同理这个过程会传递给所有相连的数据</p>
<h5 id="423-以定量的思想去定义点的smoothness">4.2.3 以定量的思想去定义点的Smoothness</h5>
<p><img src='/image/semi-15.png' /></p>
<center>为图的节点不同分类计算顺滑度
<p>我们可以定义的 图的顺滑度为 S(G) = 1/2 <img src="https://latex.codecogs.com/svg.latex?\sum&space;w_{i,&space;j}(y^i&space;-&space;y^j)^2" title="\sum w_{i, j}(y^i - y^j)^2" /> 前面的系数不重要, 通俗来说顺滑度就是所有相邻节点的label差的平方乘它们的权值 的合. <strong>Smaller means Smoother</strong></p>
<p>对于左图 : S = 0.5</p>
<p>对于右图 : S = 3</p>
<p><strong>计算出来明显左图的顺滑度更高, 所以更符合要求</strong></p>
<h5 id="424-给模型添加有s项的损失函数">4.2.4 给模型添加有S项的损失函数</h5>
<p><strong>简化S函数</strong> :</p>
<p><img src="https://latex.codecogs.com/svg.latex?S(G)&space;=&space;1/2&space;\sum&space;w_{i,&space;j}(y^i&space;-&space;y^j)^2&space;=&space;y^TL&space;y" title="S(G) = 1/2 \sum w_{i, j}(y^i - y^j)^2 = y^TL y" /></p>
<p>其中 L (Graph Laplacian) = D - W</p>
<p>以上图为例 :</p>
<p><img src='/image/semi-16.png' /></p>
<center>上图的L求解
<p>W 就是这个图的连接矩阵, D 就是 <strong>W每一行的和放在了对角线的位置</strong></p>
<p>从而定义 L = D - W</p>
<p>从而可以给我们的模型的损失函数loss function添加一项 s:</p>
<p>New_loss = old_loss + $\alpha$S 从而将此方法应用到我们的模型训练中</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">LYR</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        2021-08-14
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      
      <nav class="post-nav">
        <a class="prev" href="/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/classification/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">分类</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/regression/">
            <span class="next-text nav-default">回归</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:lyr-2000@qq.com" class="iconfont icon-email" title="email"></a>
  <a href="http://doc.lyr-2000.xyz/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2021<span class="heart"><i class="iconfont icon-heart"></i></span><span>lyr</span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.c99b103c33d1539acf3025e1913697534542c4a5aa5af0ccc20475ed2863603b.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        tags: 'ams',
        }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js" integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin="anonymous"></script>






<script src="/js//custom/latex_plugin.js"></script>


</body>
</html>
