<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>分类 - Even - A super concise theme for Hugo</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="LYR" /><meta name="description" content="分类(classification) 基于生成模型 Bayes-decision-rule 基于判别模型 intro 什么是判别模型 minimun-distance-classifier Bayes decision rule 什么是贝叶斯公式 已知事件A,B发生的概率分别为 P(A), P(B), 那么" /><meta name="keywords" content="LYR的文档站, LYR的个人博客, even" />






<meta name="generator" content="Hugo 0.86.0 with theme even" />


<link rel="canonical" href="http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/classification/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.b5a744db6de49a86cadafb3b70f555ab443f83c307a483402259e94726b045ff.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="分类" />
<meta property="og:description" content="分类(classification) 基于生成模型 Bayes-decision-rule 基于判别模型 intro 什么是判别模型 minimun-distance-classifier Bayes decision rule 什么是贝叶斯公式 已知事件A,B发生的概率分别为 P(A), P(B), 那么" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/classification/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-08-14T22:43:02+08:00" />
<meta property="article:modified_time" content="2021-08-14T22:43:02+08:00" />

<meta itemprop="name" content="分类">
<meta itemprop="description" content="分类(classification) 基于生成模型 Bayes-decision-rule 基于判别模型 intro 什么是判别模型 minimun-distance-classifier Bayes decision rule 什么是贝叶斯公式 已知事件A,B发生的概率分别为 P(A), P(B), 那么"><meta itemprop="datePublished" content="2021-08-14T22:43:02+08:00" />
<meta itemprop="dateModified" content="2021-08-14T22:43:02+08:00" />
<meta itemprop="wordCount" content="2200">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="分类"/>
<meta name="twitter:description" content="分类(classification) 基于生成模型 Bayes-decision-rule 基于判别模型 intro 什么是判别模型 minimun-distance-classifier Bayes decision rule 什么是贝叶斯公式 已知事件A,B发生的概率分别为 P(A), P(B), 那么"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">LYR的文档站</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">首页</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">归档页</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">标签</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">分类</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">关于</li>
      </a><a href="/friends">
        <li class="mobile-menu-item">大佬</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">LYR的文档站</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">首页</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">归档页</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">标签</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">分类</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">关于</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/friends">大佬</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">分类</h1>

      <div class="post-meta">
        <span class="post-time"> 2021-08-14 </span>
        
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#分类classification">分类(classification)</a></li>
        <li><a href="#bayes-decision-rule">Bayes decision rule</a>
          <ul>
            <li><a href="#什么是贝叶斯公式">什么是贝叶斯公式</a></li>
            <li><a href="#贝叶斯公式的小例子">贝叶斯公式的小例子</a></li>
            <li><a href="#贝叶斯方法在机器学习分类中的应用">贝叶斯方法在机器学习分类中的应用</a></li>
            <li><a href="#bayes-方法优缺点">Bayes 方法优缺点</a></li>
          </ul>
        </li>
        <li><a href="#intro-to-判别模型-discrimitive-model">Intro to 判别模型 (Discrimitive Model)</a>
          <ul>
            <li><a href="#利用判别模型的例子">利用判别模型的例子</a></li>
            <li><a href="#线性判别式-linear-discriminant-function">线性判别式 (Linear discriminant function)</a></li>
          </ul>
        </li>
        <li><a href="#最小距离分类器minimun-distance-classifier">最小距离分类器(minimun-distance classifier)</a>
          <ul>
            <li><a href="#原理">原理</a></li>
            <li><a href="#实现公式">实现公式</a></li>
            <li><a href="#图示">图示</a></li>
            <li><a href="#分段线性判别式-piece-wise-linear-discriminant-function">分段线性判别式 (Piece-wise linear discriminant function)</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <h2 id="分类classification">分类(classification)</h2>
<p>基于生成模型</p>
<ul>
<li>Bayes-decision-rule</li>
</ul>
<p>基于判别模型</p>
<ul>
<li>intro 什么是判别模型</li>
<li>minimun-distance-classifier</li>
</ul>
<h2 id="bayes-decision-rule">Bayes decision rule</h2>
<h3 id="什么是贝叶斯公式">什么是贝叶斯公式</h3>
<p>已知事件A,B发生的概率分别为 P(A), P(B), 那么两者的相互的条件概率(conditional probability)分别可以表示为: P(A|B) , P(B|A).</p>
<p>P(A|B) = <img src="https://latex.codecogs.com/svg.latex?\frac{P(A&space;\&B)}{P(B)}" title="\frac{P(A \&B)}{P(B)}" />   得出 P(A &amp; B)  = P(A|B) * P(B)</p>
<p>P(B|A) = <img src="https://latex.codecogs.com/svg.latex?\frac{P(A&space;\&B)}{P(A)}" title="\frac{P(A \&B)}{P(A)}" />   得出 P(A &amp; B)  = P(B|A) * P(A)</p>
<p>所以可以推出 =&gt;  P(A|B) * P(B) = P(B|A) * P(A) 稍加变形就是<strong>贝叶斯公式</strong> :</p>
<h4 id="pab---img-srchttpslatexcodecogscomsvglatexfracpbapapb-titlefracpbapapb-">P(A|B)  = <img src="https://latex.codecogs.com/svg.latex?\frac{P(B|A)*P(A)}{P(B)}" title="\frac{P(B|A)*P(A)}{P(B)}" /></h4>
<h3 id="贝叶斯公式的小例子">贝叶斯公式的小例子</h3>
<p><strong>假设以硬币举例</strong></p>
<ul>
<li>假设已知硬币正面, 反面朝上的概率分别为 P(正)  P(反) 叫做 <strong>先验概率((Priori Probabilities)</strong></li>
<li>在已知先验概率的情况下, 求在硬币为某一属性 <em>X</em> 下, 正面的概率为 : P( 正 | 硬币 = X) 叫做后验概率(<strong>posterior probability</strong>)</li>
</ul>
<p>例如, 我们现在抛硬币, 且知道硬币有三种类型(数据属性) c$_1$ = 大 ,  c$_2$ = 中 , c$_3$ =  小 , 得到的结果为正, 反(输出类型), 其中30次反面, 70次正面. 在反面时, 小硬币出现6次. 正面时, 小硬币出现7次</p>
<p>所以我们的任务就是求的后验概率 <strong>当观察到硬币为小硬币, 其结果分贝为正反的概率</strong>, 根据贝叶斯公式 :</p>
<p>P(正 | 硬币 = 小) = {P(硬币 = 小| 正面) * P(正面) / P(硬币 = 小)</p>
<p>P(硬币 = 小) = <img src="https://latex.codecogs.com/svg.latex?\frac{13}{100}" title="\frac{13}{100}" /> = 0.13</p>
<p>P(硬币 = 小 | 正) = <img src="https://latex.codecogs.com/svg.latex?\frac{7}{70}" title="\frac{7}{70}" /> = 0.1</p>
<p>P(正)  = <img src="https://latex.codecogs.com/svg.latex?\frac{70}{100}" title="\frac{70}{100}" /></p>
<p>所以可以求出概率 = 0.54 , 说明<strong>当硬币是小硬币的情况下, 它抛出正面的概率为0.54</strong></p>
<h3 id="贝叶斯方法在机器学习分类中的应用">贝叶斯方法在机器学习分类中的应用</h3>
<p>这种方法假设我们已经完全知道了每个分类的 <strong>先验概率(Priori Probabilities)</strong> , 即我们知道如果结果有 <em>C</em> 类, 那么P(c$_1$) , &hellip; , P(c$_c$) 我们都知道.</p>
<p><strong>这种方法应用到机器学的分类中本质就是需要: 根据先验概率(建模时获得), 在观察到新的数据的属性X时候, 求的它的后验概率(posterior probability)的过程</strong></p>
<h4 id="bayes-算出所有类的后验概率">bayes 算出所有类的后验概率</h4>
<p>即对于所有的 <img src="https://latex.codecogs.com/svg.latex?{c$_1$,&space;...,&space;c$_w$}&space;$\in$&space;Class&space;:" title="{c$_1$, ..., c$_w$} $\in$ Class :" /></p>
<p>然后根据所有的后验概率找到最大的那一个 Max P(c$_w$ | X), 记为该数据属性的分类 c$_w$</p>
<p>P(c$_i$ | X) = <img src="https://latex.codecogs.com/svg.latex?\frac{P(X&space;|&space;c_i)&space;*&space;P(c_i)}{P(X)}" title="\frac{P(X | c_i) * P(c_i)}{P(X)}" /></p>
<p>其中 P(X) 的概率都一样 : P(X) = <img src="https://latex.codecogs.com/svg.latex?\sum_{j=1}^C&space;P(X&space;|&space;c_i)&space;*&space;P(c_i)" title="\sum_{j=1}^C P(X | c_i) * P(c_i)" /></p>
<p>所以有了结论, <strong>我们将X归于类c$_i$当且仅当</strong> (Bayes' rule minimum error):</p>
<h4 id="img-srchttpslatexcodecogscomsvglatexpxc_ispacespacepc_ispacespacepxc_kspacespacepc_kspacekspacespace1spacespacewspacekneqspacei-titlepxc_i--pc_i--pxc_k--pc_k-k--1--w-kneq-i-"><img src="https://latex.codecogs.com/svg.latex?P(x|c_i)&space;*&space;P(c_i)&space;>&space;p(x|c_k)&space;*&space;P(c_k)&space;k&space;=&space;1,&space;...,&space;w&space;k\neq&space;i" title="P(x|c_i) * P(c_i) > p(x|c_k) * P(c_k) k = 1, ..., w k\neq i" /></h4>
<h3 id="bayes-方法优缺点">Bayes 方法优缺点</h3>
<h4 id="优点">优点</h4>
<ul>
<li><strong>贝叶斯决策理论是最优的</strong>, 因为只要观测到数据属性为 <em>X</em> , 然后选择后验概率最大的结果, 就可以**最小化预测错误的概率(Bayes decision rule for minimum risk)可以证明. **这个结论对所有的观测值 <em>X</em> $\in$ All_features 都成立 , 从而可以保证预测错误的概率最小, 从而达到最优.</li>
<li><strong>可以调节先验概率和观测现象之间的平衡</strong>, 即有了Bayes方法可以使得预测结果不仅仅依赖于先验概率, 还一部分取决于观测的现象(数据属性 <em>X</em>)</li>
</ul>
<h4 id="缺点">缺点</h4>
<ul>
<li>我们通常是无法获得先验概率(prior class), 条件概率(conditional densities)等计算要件. 要获得只有从数据中进行估算(比如上面抛硬币的例子), 所有肯定和真实的概率分布有误差.</li>
<li>往往在实际中, 要观察的特征不知一个(不仅仅为大中小), 可能会面临成百上千个特征属性. 所以在计算的时候, 会遇到<strong>维度灾难(the curse of dimensionality)</strong>, 时候计算的数值很不稳定. 所以才会发展出**朴素贝叶斯方法的平滑(smoothing)**去解决这个问题</li>
</ul>
<h2 id="intro-to-判别模型-discrimitive-model">Intro to 判别模型 (Discrimitive Model)</h2>
<p>判别模型中, <strong>不用去考虑联合概率分布</strong>, 条件概率分布 等等.  而仅仅是依靠了<strong>判别式(Discirmitive function)去根据我们输入的特征向量去引导一个判别规则</strong></p>
<p>即 :<strong>判别式技术依赖于判别方程而不是数据本身的分布</strong>, 且判别式(主要参数)的形成依赖于training procedure</p>
<h3 id="利用判别模型的例子">利用判别模型的例子</h3>
<h4 id="二分类">二分类</h4>
<p>假如应对一个二分类的问题 <strong>two-class problem</strong>, 我们的判别方程为(Discirmitive function)</p>
<p>假定 x 是我们输入数据的特征向量.</p>
<p>给定一个判别方程 h(x) :</p>
<p>h(x) &gt; k =&gt; x $\in$ c$_1$</p>
<p>h(x) &lt; k =&gt; x $\in c_2$</p>
<p>(k 是一个常数)</p>
<h4 id="多分类">多分类</h4>
<p>如果是<strong>多分类的问题</strong>, 我们可以将<em>x</em>归于类$c_i$当:</p>
<p>g$_i$ (x) &gt; g$_j$(x) =&gt; x $\in c_i$ j = 1,&hellip;,C; j$\neq$ i	(即给予判别式算出来的值是最大了便可以归为这一类)</p>
<h3 id="线性判别式-linear-discriminant-function">线性判别式 (Linear discriminant function)</h3>
<p>判别式是线性模型的可以称为线性判别式 , 例如输入属性为 <em>x</em> = [x1, x2, &hellip; , x$_n$]</p>
<p>g(x) = wT<em>X</em>  + $w_0$</p>
<p>利用线性判别式的分类器可以称为 <em>Linear machines</em></p>
<h2 id="最小距离分类器minimun-distance-classifier">最小距离分类器(minimun-distance classifier)</h2>
<h3 id="原理">原理</h3>
<p>利用了 <em>Nearest-neighbour decision rule</em> 的思想 : 假定现在有n类 $c_i$ <img src="https://latex.codecogs.com/svg.latex?\in&space;c1,&space;c2&space;,&space;...,&space;c_n" title="\in c1, c2 , ..., c_n" /></p>
<p>给每一个类可以选出一个 <strong>类代表</strong> (可以是每一个类的中位数(the mean of class) etc. ) , 对应的记为 <img src="https://latex.codecogs.com/svg.latex?p_i&space;\in&space;p1,&space;...p_n" title="p_i \in p1, ...p_n" /></p>
<p>这里的 $P_i$ 维度必须和<strong>输入数据的属性维度一样</strong>, 既可以看作可输入数据一样的在<strong>坐标轴上的一个个的点</strong>, 这些点就分别代表了他们各自的类</p>
<p>现在Classifier的思想就是 : <strong>输入一个数据 <em>X</em> , 分别计算这个数据和各个点 $P_i$ 的距离$^{[1]}$, 取距离最近的那一类归位这个点的类</strong></p>
<p><small>[1] : 这个距离可以为 <strong>欧式距离, 曼哈顿距离, etc.</strong>, 但是一般在坐标轴上就是欧式距离</small></p>
<h3 id="实现公式">实现公式</h3>
<p>假设输入点为 <em>X</em>  = [x1, x2, &hellip; , x$_n$] , 点$P_i$为 P = [p1, p2, &hellip;, p$_n$]</p>
<p>那么这两点的距离可以记为 : Dis(X, P$_i$) = |X - P$_i$|$^2$  = $X^TX$ - 2$X^TP_i$  + $P_i^TP_i$</p>
<p>因此我们只需要一次计算 X 和 各个 P$_i$ 之间的取最小的距离即可</p>
<p>Min$_i$ Dis(X, P$_i$)  i $\in$ 1, 2, &hellip;. n (number of classes), 其实观察之后可以发现每个距离的第一项 $X^TX$ 等相等, 则可以不用计算, 式子变为 :</p>
<p><strong>The class assigned to is :</strong></p>
<p>$w_i$  = min$_i$(- 2$X^TP_i$  + $P_i^TP_i$)   = max$_i$($X^TP_i$  - $\frac{1}{2}P_i^TP_i$)</p>
<p>结合到我们线性分类器的公式中 :</p>
<p><img src="https://latex.codecogs.com/svg.latex?g_i(x)&space;=&space;w_i^t&space;X&space;&plus;&space;w_{i0}&space;(w_i&space;=&space;p_i&space;,&space;w_{i0}&space;=&space;-\frac{1}{2}&space;|p_i|^2)" title="g_i(x) = w_i^t X + w_{i0} (w_i = p_i , w_{i0} = -\frac{1}{2} |p_i|^2)" /></p>
<h3 id="图示">图示</h3>
<p><img src='/image/classification-M-D-classifier.png' /></p>
<ul>
<li>可以看到经过最小距离形成的决策界就是两点(prototype)连线之间的垂线(perpendicular)</li>
<li>且这个线性分类决策区域是 <strong>always convex</strong> 的</li>
</ul>
<h3 id="分段线性判别式-piece-wise-linear-discriminant-function">分段线性判别式 (Piece-wise linear discriminant function)</h3>
<ul>
<li>
<p>线性机器很简单, 但是有一个问题就是他们形成的决策界有一个问题就是, <strong>决策界是凸的 convex</strong></p>
<p>从而解决不了一些复杂的分类问题 (如下图的问题用简单的线性机器就解决不了)</p>
<p><img src='/image/classification-Piece-wise.png'  /></p>
</li>
</ul>
<p>对于分段的线性判别式, 我们的思想就是对于: <strong>每一个类, 我们可以安排多个Prototype</strong></p>
<ul>
<li>
<p>Suppose there are n$_i$ prototypes in class $w_i$  which is <img src="https://latex.codecogs.com/svg.latex?p_i^1,&space;p_i^2,&space;...&space;,&space;p_i^{n_i}" title="p_i^1, p_i^2, ... , p_i^{n_i}" /></p>
</li>
<li>
<p>然后我们将 <em>X</em> 归位类 $w_i$ 当且仅当:</p>
<p>g$<em>i$(x) = max$</em>{j=1,&hellip;,n_i}$ $g_i^j$ (x)</p>
</li>
</ul>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">LYR</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        2021-08-14
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      
      <nav class="post-nav">
        <a class="prev" href="/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/svm/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">SVM 向量机</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/semi-supvised-learning/">
            <span class="next-text nav-default">半监督学习</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:lyr-2000@qq.com" class="iconfont icon-email" title="email"></a>
  <a href="http://doc.lyr-2000.xyz/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2021<span class="heart"><i class="iconfont icon-heart"></i></span><span>lyr</span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.c99b103c33d1539acf3025e1913697534542c4a5aa5af0ccc20475ed2863603b.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        tags: 'ams',
        }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js" integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin="anonymous"></script>






<script src="/js//custom/latex_plugin.js"></script>


</body>
</html>
