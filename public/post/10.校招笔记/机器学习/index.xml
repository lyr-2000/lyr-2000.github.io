<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>机器学习 on Even - A super concise theme for Hugo</title>
    <link>http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 机器学习 on Even - A super concise theme for Hugo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>lyr</copyright>
    <lastBuildDate>Sun, 15 Aug 2021 20:59:43 +0800</lastBuildDate><atom:link href="http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ANN神经网络</title>
      <link>http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ann/</link>
      <pubDate>Sat, 14 Aug 2021 22:43:02 +0800</pubDate>
      
      <guid>http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ann/</guid>
      <description>人工神经网络(ANN) 人工神经网路在仿生上模仿(极其简单的模仿)了人脑的神经结构, 可以Learn from data. 和生成模型不同 ,神经网络不会去计算概率分</description>
    </item>
    
    <item>
      <title>pandas numpy</title>
      <link>http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%B8%B8%E7%94%A8%E5%BA%93/pandas-numpy/</link>
      <pubDate>Sat, 14 Aug 2021 22:43:02 +0800</pubDate>
      
      <guid>http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%B8%B8%E7%94%A8%E5%BA%93/pandas-numpy/</guid>
      <description>Pandas &amp;amp; Numpy Pandas ###1. Pandas 数据类型 Dataframe 1 2 3 4 d = pd.Dataframe(np.random.randn(6, 4), index = [], columns = list(&amp;#39;abcd&amp;#39;)) # 创建一个6 *4 的Dataframe类型数据 # index(行名), columns(列名) 默认</description>
    </item>
    
    <item>
      <title>SVM 向量机</title>
      <link>http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/svm/</link>
      <pubDate>Sat, 14 Aug 2021 22:43:02 +0800</pubDate>
      
      <guid>http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/svm/</guid>
      <description>支持向量机(SVM) 李宏毅 SVM 什么是SVM Support Vector Machine 一般而言是解决分类问题的,属于监督学习的一种. 通俗的说SVM就是在分类问题中那个可以 完美区分 不</description>
    </item>
    
    <item>
      <title>tensorFlow</title>
      <link>http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%B8%B8%E7%94%A8%E5%BA%93/tensorflow/</link>
      <pubDate>Sat, 14 Aug 2021 22:43:02 +0800</pubDate>
      
      <guid>http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%B8%B8%E7%94%A8%E5%BA%93/tensorflow/</guid>
      <description>TensorFlow tf.Session() tf.placeholder() TensorFlow 使用 numpy 阵列来表示张量值 !! 构建图 tf.graph() 1 2 3 a = tf.constant(3.0, dtype=tf.float32) b = tf.constant(4.0) # also tf.float32 implicitly total = a + b 这些 tf.Tensor对象仅代表将要运行的操作的结果, 并不是真</description>
    </item>
    
    <item>
      <title>分类</title>
      <link>http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/classification/</link>
      <pubDate>Sat, 14 Aug 2021 22:43:02 +0800</pubDate>
      
      <guid>http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/classification/</guid>
      <description>分类(classification) 基于生成模型 Bayes-decision-rule 基于判别模型 intro 什么是判别模型 minimun-distance-classifier Bayes decision rule 什么是贝叶斯公式 已知事件A,B发生的概率分别为 P(A), P(B), 那么</description>
    </item>
    
    <item>
      <title>半监督学习</title>
      <link>http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/semi-supvised-learning/</link>
      <pubDate>Sat, 14 Aug 2021 22:43:02 +0800</pubDate>
      
      <guid>http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/semi-supvised-learning/</guid>
      <description>半监督学习(Semi-supervised learning) 半监督学习的Classification问题 李宏毅教授半监督学习视频 知乎半监督学习笔记 1. intro 1.1 半监</description>
    </item>
    
    <item>
      <title>回归</title>
      <link>http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/regression/</link>
      <pubDate>Sat, 14 Aug 2021 22:43:02 +0800</pubDate>
      
      <guid>http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/regression/</guid>
      <description>Intro to regression 回归是常见的监督学习的算法 一般回归的问题描述: 给定一个假定映射方程(a hypothesis set) H集合 可以完成 输入变量 X 到 Y 的映射. 回归问题就是用label</description>
    </item>
    
    <item>
      <title>机器学习</title>
      <link>http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/basic/</link>
      <pubDate>Sat, 14 Aug 2021 22:43:02 +0800</pubDate>
      
      <guid>http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/basic/</guid>
      <description>Intro to Machine Learning 1. 什么是机器学习 机器学习是自动从数据中提取某种模式(patterns)的过程 机器学习是通过计算机使用 example data or past experience 来优化一个perfir</description>
    </item>
    
    <item>
      <title>机器学习概述</title>
      <link>http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/readme/</link>
      <pubDate>Sat, 14 Aug 2021 22:43:02 +0800</pubDate>
      
      <guid>http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/readme/</guid>
      <description>机器学习 目标 : 尽量用自己的话, 对机器学习的相关知识点进行归纳总结 😊😊 机器学习概念 机器学习基本概念 半监督学习 学习算法 贝叶斯分类器 三种经典线性回</description>
    </item>
    
    <item>
      <title>非监督学习的ANN</title>
      <link>http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/unsupervised-ann/</link>
      <pubDate>Sat, 14 Aug 2021 22:43:02 +0800</pubDate>
      
      <guid>http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/unsupervised-ann/</guid>
      <description>非监督学习的ANN Intro to 非监督学习ANN 属于非监督学习的ANN, 通常涉及到聚类(clustering)的过程 可以用于降低分类的过程的输入数据的</description>
    </item>
    
    <item>
      <title></title>
      <link>http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E8%B7%AF/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://doc.lyr-2000.xyz/post/10.%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E8%B7%AF/</guid>
      <description>数据预处理的基本思路 包括一下几点 : Outliers : 处理异常值 skewed features : 把偏离的数字型 feature 通过 log(feature+1) 进行转换，可以使 feature 更正常（朴素贝叶斯用到过） 为分类型 feature 创建假/模</description>
    </item>
    
  </channel>
</rss>
